<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--<base target="_blank">-->
  <title>Diganta Misra</title>
  
  <meta name="author" content="Diganta Misra">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/favicon.png">
  <script src="scramble.js"></script>
  <script src="hidebib.js" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
			MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		</script>
		<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
</head>

<body>
  <table style="width:100%;max-width:920px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tbody><tr><td>
          <p style="text-align:center">
              <img src="images/nav.gif" alt="nav_sign" width="400" height="120">
            <br>
            <br>
            <email>
                <font id="email" style="display:inline;">kai@asdneat.ldpiaang</font>
                  <script>
                emailScramble = new scrambledString(document.getElementById('email'),
                    'emailScramble', 'kai@asdneat.ldpiaang',
                    [14, 4, 2, 8, 15, 13, 1, 5, 17, 7, 6, 18, 9, 12, 16, 20, 10, 19, 11, 3]);
              </script> </email>
            
            </p>
		
		<!--<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">-->
		<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
			<tr style="padding:0px">
				<td style="padding:0px">

				<table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
					<tr style="padding:0px">
					<!--<td style="padding:2.5%;width:20%;vertical-align:middle;min-width:100px">-->
					<td style="padding:1.5%;width:16%;vertical-align:middle;text-align:center">
						<a href="index.html" target="_self">Home</a>
					</td>
					<td style="padding:1.5%;width:16%;vertical-align:middle;text-align:center">
						<a href="#news" target="_self">News</a>
					</td>
					<td style="padding:1.5%;width:16%;vertical-align:middle;text-align:center">
						<a href="#experience" target="_self">Experience</a>
					</td>
					<td style="padding:1.5%;width:16%;vertical-align:middle;text-align:center">
						<a href="#research" target="_self">Research</a>
					</td>
					<td style="padding:1.5%;width:16%;vertical-align:middle;text-align:center">
						<a href="#education" target="_self">Education</a>
					</td>
					<!-- <td style="padding:1.5%;width:16%;vertical-align:middle;text-align:center">
						<a href="members.html">People</a>
					</td> -->            
					</tr>
				</table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:top">
			  <p>
				  I am a Machine Learning Engineer at <a href="https://wandb.ai/site" target="_blank">Weights & Biases</a> where I work on the Frameworks and Integration Team. In addition I also am the <i>Founder</i> and <i>President</i> at <a href="http://landskape.ai" target="_blank">Landskape AI</a>, a theoretical and analytical deep learning non-profit research organization.
			  </p>
              <p>
                I broadly work on theoretical and analytical deep learning with focus on but not limited to the following domains:
				<ul>
					<li>Non-linear dynamics & Loss Landscapes</li>
					<li>Continual & Lifelong Learning</li>
					<li>Knowledge Distillation</li> 
					<li>Adversarial Robustness</li>
					<li>Sparsity</li>
				</ul>
              </p>
              <p>
                Presently, I am working as a Visiting Research Scholar on topics of <i>Sparsity</i> at <a href="https://vita-group.github.io/index.html" target="_blank">VITA, UT-Austin</a>, under <a href="https://spark.adobe.com/page/CAdrFMJ9QeI2y/" target="_blank">Dr. Zhangyang Wang</a>. 
				<br>
				In the past I have been fortunate to work with the likes of <a href="https://sites.google.com/site/dramritachaturvedi/home" target="_blank">Dr. Amrita Chaturvedi</a> from Indian Institute of Technology, Varanasi (IIT-BHU) in the field of biomedical data analysis and <a href="https://scholar.google.com/citations?user=iK_wjZsAAAAJ&hl=en" target="_blank">Vijay Kumar Verma</a> from <a href="https://www.isro.gov.in/" target="_blank">Indian Space Research Organization (ISRO)</a> in the domain of Genetic Algorithms.
              </p>
              <p style="padding:4.5%;text-align:center">
                <a href="data/CV.pdf" target="_blank">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=LwiJwNYAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp/&nbsp
				<a href="https://github.com/digantamisra98" target="_blank">GitHub</a> &nbsp/&nbsp
				<a href="https://blog.paperspace.com/author/diganta/" target="_blank">Blog</a> &nbsp/&nbsp
				<a href="https://twitter.com/DigantaMisra1" target="_blank">Twitter</a> &nbsp/&nbsp
				<a href="https://wandb.ai/diganta" target="_blank">W&B Profile</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/m2.png"><img style="width:100%;max-width:100%; vertical-align:top" alt="profile photo" src="images/m2.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
			<a id="news"><h2>News</h2></a>
			<p>
            <div style="width:100%;overflow-y:scroll; height:230px;">
                <ul id="news">
					<li>August 2021: Our <a href="https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/tense" target="_blank">fine grained tense modification task</a> was accepted to <a href="https://github.com/google/BIG-bench" target="_blank">Google's Big Bench</a>.</li>
					<li>July 2021: I am also joining the <a href="https://vita-group.github.io/index.html" target="_blank">VITA, UT-Austin</a> as a Visiting Research Scholar to work on sparsity under the guidance of <a href="https://spark.adobe.com/page/CAdrFMJ9QeI2y/" target="_blank">Assistant Professor Zhangyang Wang</a>.</li>
					<li>May 2021: We are organizing the Spring Edition of the <a href="https://wandb.ai/site/reproducibility-challenge" target="_blank">Weights & Biases ML Reproducibility Challenge</a>. Visit our page to learn more.</li>
					<li>January 2021: Our WACV paper's video is now out on YouTube. Watch it <a href="https://www.youtube.com/watch?v=ZW9_2bNF1zo&ab_channel=ComputerVisionFoundationVideos" target="_blank">here</a>.</li>
					<li>January 2021: I will be speaking at the <a href="https://www.youtube.com/playlist?list=PLD80i8An1OEH3ejAj8R8dy74JeSzY8kGt" target="_blank">W&B Deep Learning Salon</a> on <b>"From Smooth Activations to Robustness to Catastrophic Forgetting"</b>. &emsp; I will be joined by <a href="https://maithraraghu.com/" target="_blank">Maithra Raghu</a> from Google Brain. Watch it <a href="https://www.youtube.com/watch?v=1U-7TWysqIg" target="_blank">here</a>.</li>
					<li>December 2020: I'm starting full time as a Machine Learning Engineer at <a href="https://wandb.ai/site" target="_blank">Weights & Biases</a>.</li>
					<li>October 2020: Our paper <a href="https://openaccess.thecvf.com/content/WACV2021/html/Misra_Rotate_to_Attend_Convolutional_Triplet_Attention_Module_WACV_2021_paper.html" target="_blank">Rotate to Attend: Convolutional Triplet Attention Module</a> is accepted to <a href="http://wacv2021.thecvf.com/home" target="_blank">WACV 2021</a>.</li>
					<li>September 2020: Gave a talk on my paper on <i>Mish</i> at the <b>Robert Bosch Bangalore Research Office</b>.</li>
					<li>August 2020: I completed my Undegraduate degree in Electronics and Electrical Engineering from <a href="https://kiit.ac.in/" target="_blank">Kalinga Institute of Industrial Technology (KIIT)</a>.</li>
					<li>August 2020: Gave a talk on <i>Mish and Non-Linear Dynamics</i> at <a href="https://computervisiontalks.github.io/" target="_blank">Computer Vision Talks</a>. Watch <a href="https://youtu.be/whOdg-yrgdI" target="_blank">here</a>.</li>
					<li>July 2020: My paper <a href="https://www.bmvc2020-conference.com/assets/papers/0928.pdf" target="_blank">Mish: A Self Regularized Non-Monotonic Neural Activation Function</a> is accepted at <a href="https://www.bmvc2020-conference.com/" target="_blank">BMVC 2020</a>.</li>
					<li>July 2020: <b>CROWN: A comparison of morphology for Mish, Swish and ReLU</b> produced in collaboration with <a href="https://ideami.com/ideami/" target="_blank">Javier Ideami</a>. Watch <a href="https://www.youtube.com/watch?v=XRGu23hfzaQ" target="_blank">here</a>.</li>
					<li>May 2020: Participated in an AMA for my paper on <b>Mish</b> at the Weights & Biases reading group.</li>
					<li>April 2020: Presented my views and discussed about Data Science on the <a href="https://anchor.fm/theworldisendingpodcast" target="_blank">The World is Ending Podcast</a>. Listen to the episode <a href="https://anchor.fm/theworldisendingpodcast/episodes/Chatting-with-a-data-Science-team-ft-DeepWrex-Technologies-eco2u6" target="_blank">here</a>.</li>
					<li>February 2020: Talk on <i>Mish and Non-Linear Dynamics</i> at <a href="https://www.sicara.ai/" target="_blank">Sicara</a> is out now. Watch <a href="https://youtu.be/T2CRFROKcLM" target="_blank">here</a>.</li>
					<li>February 2020: Podcast episode on Mish at <a href="">Machine Learning Caf&eacute;</a> is out now. Listen <a href="https://open.spotify.com/episode/4sT9sxjSbAKtvJ6hTFg9zc" target="_blank">here</a>.</li>
					<li>November 2019: Presented a talk on my paper on <i>Mish</i> at the <b>University of Athens</b>.</li>
                </ul>
            </div>
			</p>
          </tr>
        </tbody></table>

		<br>
		<br>
		<br>
        
        <table width="100%" border="0" cellspacing="15" cellpadding="10">
          <a id="experience"><heading>&nbsp;&nbsp;&nbsp;Research Experience</heading></a>

          <tr>
            <td width="15%" valign="center" align="center"><img src="images/vita.png" alt="nthu" width="170" height="80"></td>
            <td width="85%" valign="top">
              <p>
                <span><strong>Visiting Research Scholar</strong></span><span style="float:right">Aug. 2021 - Present</span> <br>
                <em><a href="https://vita-group.github.io/index.html" target="_blank">VITA</a>, University of Texas at Austin</em>
                <br>
                Supervisor: <a href="https://spark.adobe.com/page/CAdrFMJ9QeI2y/" target="_blank"> Dr. Zhangyang Wang</a>
                <br>
				Research Area: Sparsity, Robustness and Knowledge Distillation.
				<br>
              </p>
            </td>
          </tr>

          <tr>
            <td width="15%" valign="center" align="center"><img src="images/hku.jpeg" alt="nthu" width="80" height="100"></td>
            <td width="85%" valign="top">
              <p>
                <span><strong><a href="https://www.lsr.hku.hk/member/diganta-misra/" target="_blank">Research Associate</a></strong></span><span style="float:right">Feb. 2020 - Present</span> <br>
                <em><a href="https://sites.google.com/view/xulab/home" target="_blank">Laboratory of Space Research (LSR)</a>, University of Hong Kong</em>
                <br>
                Supervisor: <a href="https://www.physics.hku.hk/people/academic/5206" target="_blank"> Dr. Quentin A. Parker</a>
                <br>
				Research Area: Computer Vision applications in PNe Exploration.
				<br>
              </p>
            </td>
          </tr>

          <tr>
            <td width="15%" valign="center" align="center"><img src="images/bu.png" alt="nthu" width="90" height="100"></td>
            <td width="85%" valign="top">
              <p>
                <span><strong>Research Intern</strong></span><span style="float:right">Jun. 2018 - Aug. 2018</span> <br>
                <em><a href="https://www.bennett.edu.in/laboratories/" target="_blank">NVIDIA AI Lab,</a> Bennett University</em>
                <br>
                Supervisors: <a href="https://www.gdeepak.com/" target="_blank">Dr. Deepak Garg</a> and <a href="https://sites.google.com/view/ksuneet/home" target="_blank">Dr. Suneet Gupta</a>
                <br>
				Research Area: Large Scale Visual Recognition.
				<br>
              </p>
            </td>
          </tr>
        </table>


		<table width="100%" border="0" cellspacing="15" cellpadding="10">
		<heading>&nbsp;&nbsp;&nbsp;Industrial and Leadership Experience</heading>

		<tr>
			<td width="15%" valign="center" align="center"><img src="images/wandb.jpeg" alt="nthu" width="80" height="80"></td>
			<td width="85%" valign="top">
			<p>
				<span><strong>Machine Learning Engineer</strong></span><span style="float:right">Dec. 2020 - Present</span> <br>
				<em><a href="https://wandb.ai/site" target="_blank">Weights & Biases</a></em>
				<br>
				Team: Frameworks and Integrations.
				<br>
			</p>
			</td>
		</tr>

		<tr>
			<td width="15%" valign="center" align="center"><img src="images/lskape.png" alt="nthu" width="80" height="80"></td>
			<td width="85%" valign="top">
			<p>
				<span><strong><a href="https://landskape.ai/member/diganta/" target="_blank">Founder, President and Researcher</a></strong></span><span style="float:right">Sept. 2019 - Present</span> <br>
				<em><a href="https://landskape.ai/" target="_blank">Landskape AI</a></em>
				<br>
				Mentors: <a href="https://sites.google.com/site/jaegulchoo/" target="_blank"> Assc. Prof. Jaegul Choo</a>, <a href="https://ideami.com/ideami/" target="_blank">Javier Ideami</a> and <a href="https://twitter.com/federicolois" target="_blank">Federico Lois</a>
				<br>
				Research Area: Analytical Deep Learning Theory.
				<br>
			</p>
			</td>
		</tr>

		<tr>
			<td width="15%" valign="center" align="center"><img src="images/paperspace.png" alt="nthu" width="80" height="80"></td>
			<td width="85%" valign="top">
			<p>
				<span><strong>Technical Content Developer</strong></span><span style="float:right">Jun. 2020 - Jan. 2021</span> <br>
				<em><a href="https://www.paperspace.com/" target="_blank">Paperspace</a></em>
				<br>
				<a href="https://blog.paperspace.com/author/diganta/" target="_blank">Blog</a>
				<br>
				Topic Area: Computer Vision (Attention Mechanisms).
				<br>
			</p>
			</td>
		</tr>
		</table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a id="research"><heading>Publication</heading></a>
              <br />*indicates equal contribution 
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

			<tr bgcolor="#ffffd0">
        	<td width="15%" valign="center" align="center"><img src="images/landskape-relu-mish-july-20-Fixed.jpg" alt="nthu" width="180" height="150"></td>
            </td>
            <td width="85%" style="padding:20px;vertical-align:middle">
                  <a class="tog" href="#mish">
                    <papertitle>Mish: A Self Regularized Non-Monotonic Neural Activation Function</papertitle>
                  </a>
                  <br>
                  <strong>Diganta Misra</strong>
                  <br>
                  <p></p>
                  <em>BMVC, 2020</em>
                  <div class="paper" id="mish2020">
                    <a class="tog" href="https://github.com/digantamisra98/Mish" target="_blank">project</a> /
                    <a href="https://www.bmvc2020-conference.com/assets/papers/0928.pdf" target="_blank">paper</a> /
                      <a class="tog" href="javascript:toggleblock('mish_abs')">abstract</a> / 
                      <a class="tog" href="javascript:toggleblock('mish_bib')">bibtex</a>
                      <p align="justify">
                        <i id="mish_abs">
                            We propose <b>Mish</b>, a novel self-regularized non-monotonic activation function which can be mathematically defined as: $f(x)=xtanh(softplus(x))$. As activation functions play a crucial role in the performance and training dynamics in neural networks, we validated experimentally on several well-known benchmarks against the best combinations of architectures and activation functions. We also observe that data augmentation techniques have a favorable effect on benchmarks like ImageNet-1k and MS-COCO across multiple architectures. For example, Mish outperformed Leaky ReLU on YOLOv4 with a CSP-DarkNet-53 backbone on average precision ($AP^{val}_{50}$) by $2.1\%$ in MS-COCO object detection and ReLU on ResNet-50 on ImageNet-1k in Top-1 accuracy by $\approx 1 \%$ while keeping all other network parameters and hyperparameters constant. Furthermore, we explore the mathematical formulation of Mish in relation with the Swish family of functions and propose an intuitive understanding on how the first derivative behavior may be acting as a regularizer helping the optimization of deep neural networks.
                        </i>
                      </p>
                      <bibtext xml:space="preserve" id="mish_bib">
						@article{misra2019mish, <br />
							title={Mish: A self regularized non-monotonic neural activation function}, <br />
							author={Misra, Diganta}, <br />
							journal={arXiv preprint arXiv:1908.08681}, <br />
							volume={4}, <br />
							pages={2}, <br />
							year={2019}, <br />
							publisher={CoRR} <br />
						  }
                            
                        </bibtext>
					<a href="https://youtu.be/whOdg-yrgdI" target="_blank">CV Talk Episode</a> /
					<a href="https://open.spotify.com/episode/4sT9sxjSbAKtvJ6hTFg9zc" target="_blank">ML Cafe Episode</a> /
					<a href="https://youtu.be/T2CRFROKcLM" target="_blank">Sicara Talk</a> /
					<a href="https://www.youtube.com/watch?v=1U-7TWysqIg" target="_blank">W&B Salon Episode</a>
					<br>
					<br>
					<a href="https://GitHub.com/digantamisra98/Mish/stargazers/" target="_blank"><img src="https://img.shields.io/github/stars/digantamisra98/Mish.svg?style=social&label=Star&maxAge=2592000"></a>
					&emsp;
					<a href="https://GitHub.com/digantamisra98/Mish/fork/" target="_blank"><img src="https://img.shields.io/github/forks/digantamisra98/Mish.svg?style=social&label=Fork&maxAge=2592000"></a>
					&emsp;
					<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwiJwNYAAAAJ&citation_for_view=LwiJwNYAAAAJ:u5HHmVD_uO8C" target="_blank"><img src="https://img.shields.io/badge/Citations-283-lightgrey.svg?style=social&logo=Google Scholar"></a>
					&emsp;
					<a href="https://console.paperspace.com/github/digantamisra98/Mish/blob/master/exps/Mish_test.ipynb" target="_blank">
					<img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Run on Gradient"/>
					</a>
                    </div>              
                    <script language="JavaScript">hideblock('mish_bib');hideblock('mish_abs');</script>
            </td>
            </tr>

			<td width="15%" valign="center" align="center"><img src="images/grad.png" alt="nthu" width="160" height="190"></td>
            </td>
            <td width="85%" style="padding:20px;vertical-align:middle">
                  <a class="tog" href="#triplet">
                    <papertitle>Rotate to Attend: Convolutional Triplet Attention Module</papertitle>
                  </a>
                  <br>
                  <strong>Diganta Misra<sup>*</sup></strong>,
				  <a href="https://scholar.google.com/citations?user=1YmHR6MAAAAJ&hl=en" target="_blank">Trikay Nalamada</a><sup>*</sup>,
				  <a href="https://iyaja.github.io/" target="_blank">Ajay Uppili Arasanipalai</a><sup>*</sup>,
				  <a href="https://andrew-qibin.github.io/homepage/" target="_blank">Qibin Hou</a>
				  <br>
                  <p></p>
                  <em>WACV, 2021</em>
                  <div class="paper" id="wacv2021">
                    <a class="tog" href="https://github.com/landskape-ai/triplet-attention" target="_blank">project</a> /
                    <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Misra_Rotate_to_Attend_Convolutional_Triplet_Attention_Module_WACV_2021_paper.pdf" target="_blank">paper</a> /
					<a href="https://openaccess.thecvf.com/content/WACV2021/supplemental/Misra_Rotate_to_Attend_WACV_2021_supplemental.pdf" target="_blank">supplementary</a> /
					<a href="https://youtu.be/ZW9_2bNF1zo" target="_blank">video</a> /
                      <a class="tog" href="javascript:toggleblock('wacv_abs')">abstract</a> / 
                      <a class="tog" href="javascript:toggleblock('wacv_bib')">bibtex</a>
                      <p align="justify">
                        <i id="wacv_abs">
                            Benefiting from the capability of building interdependencies among channels or spatial locations, attention mechanisms have been extensively studied and broadly
							used in a variety of computer vision tasks recently. In
							this paper, we investigate light-weight but effective attention mechanisms and present <b>triplet attention</b>, a novel
							method for computing attention weights by capturing crossdimension interaction using a three-branch structure. For
							an input tensor, triplet attention builds inter-dimensional
							dependencies by the rotation operation followed by residual transformations and encodes inter-channel and spatial
							information with negligible computational overhead. Our
							method is simple as well as efficient and can be easily
							plugged into classic backbone networks as an add-on module. We demonstrate the effectiveness of our method on
							various challenging tasks including image classification on
							ImageNet-1k and object detection on MSCOCO and PASCAL VOC datasets. Furthermore, we provide extensive insight into the performance of triplet attention by visually
							inspecting the GradCAM and GradCAM++ results. The
							empirical evaluation of our method supports our intuition
							on the importance of capturing dependencies across dimensions when computing attention weights.
                        </i>
                      </p>
                      <bibtext xml:space="preserve" id="wacv_bib">
						@inproceedings{misra2021rotate, <br />
						title={Rotate to attend: Convolutional triplet attention module}, <br />
						author={Misra, Diganta and Nalamada, Trikay and Arasanipalai, Ajay Uppili and Hou, Qibin}, <br />
						booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, <br />
						pages={3139--3148}, <br />
						year={2021} <br />
						}
                            
                        </bibtext>
					<a href="https://github.com/landskape-ai/triplet-attention/stargazers/" target="_blank"><img src="https://img.shields.io/github/stars/landskape-ai/triplet-attention.svg?style=social&label=Star&maxAge=2592000"></a>
					&emsp;
					<a href="https://github.com/landskape-ai/triplet-attention/fork/" target="_blank"><img src="https://img.shields.io/github/forks/landskape-ai/triplet-attention.svg?style=social&label=Fork&maxAge=2592000"></a>
					&emsp;
					<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwiJwNYAAAAJ&citation_for_view=LwiJwNYAAAAJ:UeHWp8X0CEIC" target="_blank"><img src="https://img.shields.io/badge/Citations-10-lightgrey.svg?style=social&logo=Google Scholar"></a>
                    </div>              
                    <script language="JavaScript">hideblock('wacv_bib');hideblock('wacv_abs');</script>
            </td>
			</tr>


			<td width="15%" valign="center" align="center"><img src="images/ga.jpg" alt="nthu" width="200" height="100"></td>
            </td>
            <td width="85%" style="padding:20px;vertical-align:middle">
                  <a class="tog" href="#ga">
                    <papertitle>Genetic Algorithm Optimized Inkjet Printed Electromagnetic Absorber on Paper Substrate</papertitle>
                  </a>
                  <br>
                  <strong>Diganta Misra</strong>,
				  Rahul Pelluri,
				  <a href="https://scholar.google.com/citations?user=iK_wjZsAAAAJ&hl=en" target="_blank">Vijay Kumar Verma</a>,
				  <a href="https://scholar.google.com/citations?user=iGAvOmEAAAAJ&hl=en" target="_blank">Bhargav Appasani</a>,
				  Nisha Gupta
				  <br>
                  <p></p>
                  <em>IEEE AESPC, 2018</em>
                  <div class="paper" id="ga2018">
                    <a href="data/misra2018.pdf" target="_blank">paper</a> /
                      <a class="tog" href="javascript:toggleblock('ga_abs')">abstract</a> / 
                      <a class="tog" href="javascript:toggleblock('ga_bib')">bibtex</a>
                      <p align="justify">
                        <i id="ga_abs">
                            Printable electronics based electromagnetic absorbers are receiving increasing attention of the electromagnetic community because of their unprecedented advantages. This paper presents the design of printable electromagnetic absorbers for the X band. The design of the absorber is optimized using the Genetic Algorithm (GA) to enhance the absorptivity and the absorption bandwidth. The design involves the placement of several square-shaped conductive ink at optimal locations on the paper substrate such that desired absorption characteristics are obtained. Simulations are carried out using the HFSS simulation software. The optimized structure offers an absorptivity of more than 90% in the X band thereby proving to be a viable solution for stealth applications.
                        </i>
                      </p>
                      <bibtext xml:space="preserve" id="ga_bib">
						@inproceedings{misra2018genetic, <br />
						title={Genetic Algorithm Optimized Inkjet Printed Electromagnetic Absorber on Paper Substrate}, <br />
						author={Misra, Diganta and Pelluri, Rahul and Verma, Vijay Kumar and Appasani, Bhargav and Gupta, Nisha}, <br />
						booktitle={2018 International Conference on Applied Electromagnetics, Signal Processing and Communication (AESPC)}, <br />
						volume={1}, <br />
						pages={1--3}, <br />
						year={2018}, <br />
						organization={IEEE} <br />
						}
                            
                        </bibtext>
                    </div>              
                    <script language="JavaScript">hideblock('ga_bib');hideblock('ga_abs');</script>
            </td>
		</tr>
          
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research under progress</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

			<td width="25%" valign="center" align="center"><img src="images/ensemble.gif" alt="nthu" width="160" height="160"></td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a class="tog" href="#ensemble">
                  <papertitle>Inspecting Ensembles under a microscope</papertitle>
                </a>
                <br>
                <a href="https://awasay.github.io/" target="_blank">Abdul Wasay<sup>*</a>,
                <strong>Diganta Misra<sup>*</strong>
                <br>
                <p></p>
              </td>
            </tr>

			<td width="25%" valign="center" align="center"><img src="https://i.gifer.com/AEyH.gif" alt="nthu" width="160" height="160"></td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a class="tog" href="#prune">
                  <papertitle>Anytime Pruning</papertitle>
                </a>
                <br>
                <a href="https://tianlong-chen.github.io/about/" target="_blank">Tianlong Chen</a>,
                <strong>Diganta Misra</strong>,
				<a href="https://spark.adobe.com/page/CAdrFMJ9QeI2y/" target="_blank">Zhangyang Wang</a>
                <br>
                <p></p>
              </td>
            </tr>

			<td width="25%" valign="center" align="center"><img src="https://i.gifer.com/IQ35.gif" alt="nthu" width="160" height="160"></td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a class="tog" href="#mirv2">
                  <papertitle>Image Enhancement under resource constraints</papertitle>
                </a>
                <br>
				<strong>Diganta Misra</strong>,
				<a href="https://iyaja.github.io/" target="_blank">Ajay Uppili Arasanipalai</a>,
				<a href="https://sauravmaheshkar.github.io/" target="_blank">Saurav Maheshkar</a>,
                <a href="https://bharat-runwal.netlify.app/" target="_blank">Bharat Runwal</a>
                <br>
                <p></p>
              </td>
            </tr>

			<td width="25%" valign="center" align="center"><img src="images/act.gif" alt="nthu" width="160" height="160"></td>
			<td style="padding:20px;width:75%;vertical-align:middle">
				<a class="tog" href="#continual">
				<papertitle>Stability-Plasticity-Uncertainty Criterion</papertitle>
				</a>
				<br>
				<a href="https://it.linkedin.com/in/norman-di-palo" target="_blank">Norman Di Palo</a>,
				<a href="https://ca.linkedin.com/in/himanshuarora93" target="_blank">Himanshu Arora</a>,
				<strong>Diganta Misra</strong>,
				<a href="https://in.linkedin.com/in/mukundvarmat" target="_blank">Mukund Varma T</a>
				<br>
				<p></p>
			</td>
			</tr>

			<td width="25%" valign="center" align="center"><img src="images/3M3T.gif" alt="nthu" width="160" height="160"></td>
			<td style="padding:20px;width:75%;vertical-align:middle">
				<a class="tog" href="#rsep">
				<papertitle>R-Separation Dataset Distillation</papertitle>
				</a>
				<br>
				<strong>Diganta Misra</strong>,
				<a href="https://www.yash-sharma.com/" target="_blank">Yash Sharma</a>
				<br>
				<p></p>
			</td>
			</tr>

			<td width="25%" valign="center" align="center"><img src="images/mlip.gif" alt="nthu" width="160" height="160"></td>
			<td style="padding:20px;width:75%;vertical-align:middle">
				<a class="tog" href="#act">
				<papertitle>Non-monotonicity through a lens</papertitle>
				</a>
				<br>
				<strong>Diganta Misra</strong>
				<br>
				<p></p>
			</td>
			</tr>


			<td width="25%" valign="center" align="center"><img src="images/concov.gif" alt="nthu" width="160" height="160"></td>
			<td style="padding:20px;width:75%;vertical-align:middle">
				<a class="tog" href="#gram">
				<papertitle><b>C-GRAM</b>: Estimating model performance using gramian thresholds</papertitle>
				</a>
				<br>
				<a href="https://weijiandeng.xyz/" target="_blank">Weijian Deng</a>,
				<strong>Diganta Misra</strong>,
				<a href="http://zheng-lab.cecs.anu.edu.au/" target="_blank">Liang Zheng</a>
				<br>
				<p></p>
			</td>
			</tr>

        </tbody></table>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Open Source Frameworks & Projects</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <td width="25%" valign="center" align="center"><img src="images/avalanche.png" alt="nthu" width="180" height="160"></td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a class="tog" href="https://github.com/ContinualAI/avalanche" target="_blank">
              <papertitle>Avalanche: an End-to-End Library for Continual Learning</papertitle>
            </a>
            <br>
            Dec'20 - Present
            <br>
            <br>
            I am an active lead maintainer of the Reproducible Continual Learning framework by Avalanche and
			also actively work on the evaluation framework of Avalanche mainly in the direction of integration of Weights & Biases API. 
            <br>
			<br>
			<a href="https://github.com/ContinualAI/avalanche/stargazers/" target="_blank"><img src="https://img.shields.io/github/stars/ContinualAI/avalanche.svg?style=social&label=Star&maxAge=2592000"></a>
			&emsp;
			<a href="https://github.com/ContinualAI/avalanche/fork/" target="_blank"><img src="https://img.shields.io/github/forks/ContinualAI/avalanche.svg?style=social&label=Fork&maxAge=2592000"></a>
			&emsp;
			<a href="https://avalanche-api.continualai.org/" target="_blank"><img src="https://img.shields.io/badge/docs-passing?style=social&logo=Read the Docs"></a>
            <p></p>
            
          </td>
        </tr>

		<td width="25%" valign="center" align="center"><img src="images/echo.png" alt="nthu" width="160" height="170"></td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a class="tog" href="https://github.com/digantamisra98/Echo" target="_blank">
              <papertitle>Echo</papertitle>
            </a>
            <br>
            Jun'19 - Present
            <br>
            <br>
			Echo is an OSS deep learning package with support for TensorFlow, PyTorch and MegEngine, containing novel validated methods, components and building blocks used in deep learning.
            <br>
			<br>
			<a href="https://GitHub.com/digantamisra98/Echo/stargazers/" target="_blank"><img src="https://img.shields.io/github/stars/digantamisra98/Echo.svg?style=social&label=Star&maxAge=2592000"></a>
			&emsp;
			<a href="https://GitHub.com/digantamisra98/Echo/fork/" target="_blank"><img src="https://img.shields.io/github/forks/digantamisra98/Echo.svg?style=social&label=Fork&maxAge=2592000"></a>
			&emsp;
			<a href="https://pypi.python.org/pypi/echoAI" target="_blank"><img src="https://img.shields.io/pypi/dm/echoAI.svg?style=social&logo=PyPI"></a>
			&emsp;
			<a href="https://xa9ax.gitbook.io/echo/" target="_blank"><img src="https://img.shields.io/badge/docs-passing?style=social&logo=Read the Docs"></a>
            <p></p>
            
          </td>
        </tr>

		<td width="25%" valign="center" align="center"><img src="images/evonorm.png" alt="nthu" width="250" height="120"></td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a class="tog" href="https://github.com/digantamisra98/EvoNorm" target="_blank">
			<papertitle>Evonorm</papertitle>
			</a>
			<br>
			Apr'20
			<br>
			<br>
			Created the most popular open source reimplementation of <a href="https://arxiv.org/abs/2004.02967" target="_blank">Evolving Normalization-Activation Layers</a> by Liu. et. al.
			<br>
			<br>
			<a href="https://GitHub.com/digantamisra98/Evonorm/stargazers/" target="_blank"><img src="https://img.shields.io/github/stars/digantamisra98/Evonorm.svg?style=social&label=Star&maxAge=2592000"></a>
			&emsp;
			<a href="https://GitHub.com/digantamisra98/Evonorm/fork/" target="_blank"><img src="https://img.shields.io/github/forks/digantamisra98/Evonorm.svg?style=social&label=Fork&maxAge=2592000"></a>
			<p></p>

		</td>
		</tr>

		<td width="25%" valign="center" align="center"><img src="images/BIG-bench.png" alt="nthu" width="120" height="120"></td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a class="tog" href="https://github.com/google/BIG-bench" target="_blank">
			<papertitle>Big Bench</papertitle>
			</a>
			<br>
			Aug'21
			<br>
			<br>
			Our <a href="https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/tense" target="_blank">fine grained tense modification task</a> was accepted to <a href="https://github.com/google/BIG-bench" target="_blank">Google's Big Bench</a> for testing large LMs. In collaboration with <a href="https://in.linkedin.com/in/mukundvarmat" target="_blank">Mukund Varma T.</a>
			<br>
			<br>
			<a href="https://GitHub.com/google/BIG-bench/stargazers/" target="_blank"><img src="https://img.shields.io/github/stars/google/BIG-bench.svg?style=social&label=Star&maxAge=2592000"></a>
			&emsp;
			<a href="https://GitHub.com/google/BIG-bench/fork/" target="_blank"><img src="https://img.shields.io/github/forks/google/BIG-bench.svg?style=social&label=Fork&maxAge=2592000"></a>
			<p></p>

		</td>
		</tr>


        </tbody></table>

		<br>
		<br>


		<table width="100%" border="0" cellspacing="15" cellpadding="10">
		<a id="education"><heading>&nbsp;&nbsp;&nbsp;Education</heading></a>

		<tr>
			<td width="15%" valign="center" align="center"><img src="images/kiit.jpg" alt="nthu" width="130" height="100"></td>
			<td width="85%" valign="top">
			<p>
				<span><strong>Bachelors of Technology (B.Tech) in EEE</strong></span><span style="float:right">Jun. 2016 - May. 2020</span> <br>
				<em><a href="https://kiit.ac.in/" target="_blank">Kalinga Institute of Industrial Technology (KIIT)</a></em>
				<br>
				Advisor: <a href="https://scholar.google.com/citations?user=iGAvOmEAAAAJ&hl=en" target="_blank">Asst. Prof. Dr. Bhargav Appasani</a>
				<br>
				Bhubaneswar, India
			</p>
			</td>
		</tr>
		</table>


		<table width="100%" border="0" cellspacing="15" cellpadding="10">
			<heading>&nbsp;&nbsp;&nbsp;Internships and Exchange Programs</heading>
	
			<tr>
				<td width="15%" valign="center" align="center"><img src="images/csir.png" alt="nthu" width="120" height="120"></td>
				<td width="85%" valign="top">
				<p>
					<span><strong>Data Sciene Intern</strong></span><span style="float:right">Jun. 2018 - Feb. 2019</span> <br>
					<em><a href="https://cdri.res.in/" target="_blank">CSIR-CDRI</a></em>
					<br>
					<br>
					During this internship, I was involved in building the analytical pipeline, data collection, pre-processing of data, cleaning of data, Geo-spatial Analysis of data and Document writing for the project on understanding demographics of Venture Capital and
					Early Seed Investments. As a part of a team of three, I was advised and mentored by <a href="http://brainnart.com/" target="_blank">Dr. Sukant Khurana</a>.
					<br>
					<br>
					Remote
				</p>
				</td>
			</tr>
	
			<tr>
				<td width="15%" valign="center" align="center"><img src="images/kgp.png" alt="nthu" width="120" height="120"></td>
				<td width="85%" valign="top">
				<p>
					<span><strong>Summer Intern</strong></span><span style="float:right">May. 2018 - Jun. 2018</span> <br>
					<em><a href="http://www.iitkgp.ac.in/" target="_blank">IIT-Kharagpur</a></em>
					<br>
					<br>
					Studied basic algorithmic techniques using functional programming languages - Lisp
					and Prolog under the guidance of <a href="http://www.iitkgp.ac.in/department/MA/faculty/ma-pawan#resp-tab1" target="_blank">Assc. Prof. Pawan Kumar</a>.
					<br>
					<br>
					Kharagpur, India
				</p>
				</td>
			</tr>
	
			<tr>
				<td width="15%" valign="center" align="center"><img src="images/bangkok.png" alt="nthu" width="120" height="120"></td>
				<td width="85%" valign="top">
				<p>
					<span><strong>Summer Exchange Intern</strong></span><span style="float:right">Jun. 2017 - Aug. 2017</span> <br>
					<em><a href="https://www.bu.ac.th/en/international-programs" target="_blank">Bangkok University</a></em>
					<br>
					<br>
					Served as a primary instructor for cultural engagements along with teaching basic
					english and computer science to primary grade students at RangsonWittaya School,
					Nakhon Sawan under the <a href="https://aiesec.org/" target="_blank">AIESEC</a> SDG #4 programme. Was also part of culture
					exchange, entrepreneurship and social service programs at Bangkok University
					<br>
					<br>
					Bangkok, Thailand
				</p>
				</td>
			</tr>
			</table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Initiatives and Academic Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/nma1.jpeg" height="80" width="160"></td>
            <td width="75%" valign="center">
                <a href="https://academy.neuromatch.io/" target="_blank">
                    <papertitle>NeuroMatch Academy</papertitle>
                </a>
                <br>
                <br>
				I am responsible for developing the content for the Strategies section in the Continual Learning lecture of the Deep Learning Cohort of Neuromatch Academy 2021.
              
            </td>
          </tr>
          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/wandb.jpeg" height="120" width="120"></td>
              <td width="75%" valign="center">
                  <a href="https://wandb.ai/site/reproducibility-challenge" target="_blank">
                      <papertitle>W&B ML Reproducibility Challenge</papertitle>
                  </a>
                  <br>
                  <br>
                  I am the lead organizer of the W&B MLRC 2021 where I actively support our challenge participants. Our mission of organizing this challenge is 
																		to make machine learning research reproducible, transparent and accessible to everyone. This initiative is also supported by our W&B MLRC Grant of $500 for each participant.
                
              </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:left;font-size:small;">
                  Updated on: 10th August, 2021
    
              <span style="float:right;">
                Merci, <a href="https://jonbarron.info/" target="_blank">Jon Barron</a>!
              </span>
                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
</body>

</html>
