---
layout: default
---


<div class="home">

<!--   <table style="text-align: left; width: 90%;" border="0" cellpadding="2" cellspacing="2"> --> 

<table style="text-align: left;" border="0">
    <tbody>
      <tr>
        <td style="width=20%;vertical-align: top;">
        <!--img title="Istanbul, 2013", style="max-width:200px;" alt="That's me." src="ioannis-headshot-scaled.jpg"></td-->
        <img title="Ioannis", style="width:100%;" alt="That's me." src="ioannis-headshot-scaled.jpg">
	<br>
	<br>
        <img title="UdeM", style="width:50%;" alt="UdeM" src="images/logo-udem.png">
	<br>
	Assistant professor,
	Computer Science,
	University of Montr&eacute;al
	<br>
	<br>
	<a href="https://mila.quebec/" target="_blank">
        <img title="Mila", style="width:40%;" alt="Mila" src="images/logo-mila.png">
	<br>
	Core faculty at Mila
	<br>
	<br>
	</a>
	<a href="https://www.cifar.ca/ai/pan-canadian-artificial-intelligence-strategy/the-canada-cifar-ai-chairs" target="_blank">
        <img title="CIFAR", style="width:30%;" alt="CIFAR" src="images/logo-cifar.jpg">
	<br>
	Recipient of Canada CIFAR AI Chair 
	</a>
	<br>
	<br>


	</td>
        <td width=30px></td>
        <td style="vertical-align: top;">
	I work on topics in optimization, dynamics and learning, 
	with a focus on modern machine learning. 
	I have done work in the intersection of systems and theory.
	<!--I am interested in systems for modern machine learning and data analysis.-->
	Some recent topics:
	<ul>
		<li>Min-max optimization and the dynamics of games</li>
		<li>Generalization and domain adaptation</li>
		<li>Optimization for deep learning</li> 
		<li>Statistical learning and inference</li>
	</ul>

	<center>
		See my <a href="rs.pdf" target="_blank">research statement</a>
		for long-term vision 
		and  <a href="https://scholar.google.com/citations?hl=en&user=K757SxgAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">recent publications</a>
		for an idea of what I'm doing now
	</center> 
	<br>

	Before joining the University of Montreal, I was a postdoc with the Departments of Computer Science and Statistics at Stanford University
        working with <a href="http://cs.stanford.edu/people/chrismre/" target="_blank">Chris R&eacute;</a> and <a href="http://web.stanford.edu/~lmackey/" target="_blank">Lester Mackey</a>.
	I got my PhD at The University of Texas at Austin with <a href="http://users.ece.utexas.edu/%7Ecmcaram/" target="_blank">Constantine Caramanis</a> and <a href="http://www.ece.utexas.edu/people/faculty/sriram-vishwanath" target="_blank">Sriram Vishwanath</a>,
	 where I also worked with <a href="http://users.ece.utexas.edu/~dimakis/" target="_blank">Alex Dimakis</a>.
	<br>
	<br>

	<center>
		CV (January 2020) <a href="cv.pdf" target="_blank">here</a>
	<br>
	<br>
	</center>

	<font color="red" style="font-weight:bold">
		Prospective students: 
	</font>
	I am looking for particularly strong students, for MSc or PhD.
	<!--Unfortunatley, I might not be able to respond to all emails.-->
	Please make sure to go over my  
	<a href="https://scholar.google.com/citations?hl=en&user=K757SxgAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">recent publications</a>
	and list of recent projects (below). 
	If you think that we have a good overlap in interests
	and you have already done research in the area feel free to email me. 
<!--	a strong background in mathematics and computation,
	please make sure to submit
	your <a href="https://mila.quebec/en/cours/admission/" target="_blank">supervision request</a> 
	by December 15th and mention me as one of your faculty of choice.-->
	<br>
	<br>
	<a href="mailto:ioannis@iro.umontreal.ca" target="_blank">Email,</a>
	<a href="https://scholar.google.com/citations?user=K757SxgAAAAJ&hl=en&oi=ao" target="_blank">Scholar,</a>
	<a href="https://twitter.com/bouzoukipunks" target="_blank">Twitter,</a>
	<a href="https://www.linkedin.com/in/ioannis-mitliagkas-6a8241131/" target="_blank">LinkedIn</a>


	
	<br>


	</td>
        <!-- <img style="width: 200px; height: 300px;" alt="That's me." src="colourPortrait.jpg"></td>
         --><td style="vertical-align: top;">&nbsp;&nbsp; <br>
        </td>
      </tr>
    </tbody>
  </table>

<h2>Teaching</h2> 

<ul>
	<li>Winter 2020: <a href="/ift6085-dl-theory-class-2020/">
			IFT 6085 - Theoretical principles for deep learning
		</a>
	<li>Fall 2019: <a href="/ift6390-ml-class-2019/">
			IFT 6390 - Fundamentals of Machine Learning (Fondements de l'apprentissage machine)
		</a>
	<li>Winter 2019: <a href="/ift6085-dl-theory-class-2019/">
			IFT 6085 - Theoretical principles for deep learning
		</a>
	<li>Fall 2018: <a href="/ift6390-ml-class-2019/">
			IFT 6390 - Fundamentals of Machine Learning (Fondements de l'apprentissage machine)
		</a>
	<li>Winter 2018: <a href="/ift6085-dl-theory-class/">
			IFT 6085 - Theoretical principles for deep learning
		</a>
</ul>
			

<h2>Recent projects</h2>
<div id="imagelist">
    <ul>
      <li>
      <li>
      <a href="https://www.bradyneal.com/bias-variance-tradeoff-textbooks-update" target="_blank">
      <img src="{{ site.baseurl }}/images/project-bias-variance.png" alt="" title="A Modern Take on the Bias-Variance Tradeoff in Neural Networks">
      <div>
        A Modern Take on the Bias-Variance Tradeoff in Neural Networks
        <em>
	We measure neural network prediction bias and variance.
	We find that both bias and variance can decrease as the number of parameters
	grows. We decompose the total variance into
	variance due to training set sampling and variance due to initialization.
	</em>
      </div></a>
      </li> 
      <li>
      <li>
      <a href="https://arxiv.org/pdf/1807.04740.pdf"  target="_blank">
      <img src="{{ site.baseurl }}/images/project-negative-momentum.png" alt="" title="Negative Momentum for Improved Game Dynamics">
      <div>
        Negative Momentum for Improved Game Dynamics
        <em>
	Alternating updates are more stable than
	simultaneous updates on simple games.
	A negative momentum
	term achieves convergence in a difficult toy adversarial problem, but also on the notoriously
	difficult to train saturating GANs
	</em>
      </div></a>
      </li> 
      <li>
      <li>
      <a href="https://facebook.com/icml.imls/videos/live-from-icml-2019-in-long-beach-this-session-on-deep-generative-models-include/1269891676506524/"  target="_blank">
      <img src="{{ site.baseurl }}/images/project-state-reification.png" alt="" title="State-Reification Networks">
      <div>
	     State-Reification Networks
        <em>
	     Improving Generalization
	by Modeling the Distribution of Hidden Representations
	</em>
      </div></a>
      </li> 
      <li>
      <a href="https://arxiv.org/abs/1707.02670" target="_blank">
      <img src="{{ site.baseurl }}/images/pca.png" alt="" title="Accelerated power iteration">
      <div>
	Accelerated stochastic power iteration
        <em>Exciting recent results on how adding a momentum term to the power iteration yields a numerically stabe, accelerated method.</em>
      </div></a>
      </li> 
      <li>
      <a href="http://dawn.cs.stanford.edu/2017/07/05/yellowfin/"  target="_blank">
      <img src="{{ site.baseurl }}/images/Yellowfin.png" alt="" title="Self-tuning!">
      <div>
	YellowFin: Self-tuning optimization for deep learning
        <em>Simple insights on the momentum update yield an very efficient parameter-free algorithm that performs well across networks and datasets without the need to tune any parameters.</em>
      </div></a>
      </li> 
      <li>
      <a href="https://arxiv.org/abs/1707.02392"  target="_blank">
      <img src="{{ site.baseurl }}/images/shape-analogies.png" alt="" title="Representation and generation">
      <div>
	Representation Learning and Adversarial Generation of 3D Point Clouds
        <em>The first AutoEncoder design suited to 3D point cloud data beats state of the art in reconstruction accuracy. 
		GANs trainined in the AE's latent space generate realistic objects from every-day classes.
		</em>
      </div></a>
      </li> 
      <li>
      <a href="https://arxiv.org/pdf/1708.05256.pdf"  target="_blank">
      <img src="{{ site.baseurl }}/images/project-15pf.png" alt="" title="Deep Learning at 15 Petaflops">
      <div>
        Deep Learning at 15 Petaflops
        <em>15-PetaFLOP Deep Learning system for solving scientific pattern classification problems on contemporary HPC architectures</em>
      </div></ak>
      </li> 
      <li>
      <a href="https://arxiv.org/pdf/1707.05807.pdf" target="_blank">
      <img src="{{ site.baseurl }}/images/graph.png" alt="Gibbs Sampling Scan Order" title="[redacted]">
      <div>
	Gibbs Sampling Scan Order
	<em>Our NIPS 2016 work shows that scan order matters.<br>
	Now we show that it is possible to make Gibbs sampling many orders of magnitude faster by customizing the scan sequence to a specific model and given set of target variables.</em>
      </div></a>
      </li> 
      <li>
      <a href="{{ site.baseurl}}/asynchrony/" target="_blank">
      <img src="{{ site.baseurl }}/images/theory-prediction.png" alt="Tuning parallel deep learning systems" title="Optimal momentum values for different levels of parallelization">
      <div>
	 Asynchrony and Momentum
        <em>When training large scale systems asynchronously, you get a momentum surprise.</em>
      </div></a>
      </li>
      <li>
      <!--a href="{{ site.baseurl}}/frogwild/">
      <img src="{{ site.baseurl }}/images/frog.png" alt="Picture of cute yet slightly deranged frog." title="Ribbit!">
      <div>
        FrogWild!
        <em>Fast PageRank approximations on Graph Engines</em>
      </div></a-->
      </li> 
    </ul>
  </div> 
  <br><br>

  <h2>Recent News</h2>
  <div id="" style="overflow-y:scroll; height:230px;">
  <ul>
		<li>January 2020: Two papers on efficient methods and tight bounds for differentiable games 
			(<a href="https://arxiv.org/pdf/2001.00602.pdf">one</a>, 
			<a href="https://arxiv.org/pdf/1906.05945.pdf">two</a>)
			accepted at AISTATS'20.
		<li>December 2019: Nicolas Loizou was awarded the IVADO postdoctoral scholarship at the prestigious Fellow tier.
		<li>December 2019: Brady Neal graduates with an MSc. He will continue on his PhD with us.
		<li>November 2019: Excited to be coorganizing the 2nd iteration of the <a href="https://sgo-workshop.github.io/">Smooth Games Optimization and Machine Learning Workshop</a> at NeurIPS'19.
		<li>November 2019: <a href="https://arxiv.org/abs/1906.03532">Reducing the variance in online optimization by transporting past gradients</a> selected for
		       	<span style="font-weight:bold">
			<font color="red">
				spotlight oral presentation	
			</font>
			</span> 
			at NeurIPS'19.
		<li>October 2019: Multiple submissions to AISTATS. Preprints on the way...
		<li>June 2019: At ICML with 3 papers in main conference, 2 in Deep Learning Phenomena workshop.
		<li>May 2019: <a href="https://arxiv.org/pdf/1905.11382.pdf">State-Reification Networks</a> selected for
		       	<span style="font-weight:bold">
			<font color="red">
				oral presentation	
			</font>
			</span> 
			at ICML'19.
		<li>April 2019: Excited to be <a href="https://i.redd.it/kovwct2jeix21.png">listed</a> among the most prolific authors of accepted ICML 2019 papers.
		<li>April 2019: I received the NSERC Discovery grant!
		<li>April 2019: In Japan for AISTATS.
		<li>January 2019: h-detach paper accepted at ICLR.
		<li>December 2018: Was nominated in the first cohort of Canada CIFAR AI chairs!!
		<li>December 2018: Co-organizing <a href="https://sgo-workshop.github.io/">Smooth Games Optimization in ML</a> workshop at NeurIPS.
		<li>December 2018: Negative momentum for improved game dynamics. Paper accepted at AISTATS 2019.
		<li>December 2018: Full version of YellowFin manscript accepted at SysML
		<li>September 2018: Excited to be teaching Machine Learning to a class of 180 graduate students at UdeM.
		<li>February 2018: <a href="https://arxiv.org/pdf/1706.03471.pdf">YellowFin</a> selected for
		       	<span style="font-weight:bold">
			<font color="red">
				oral presentation	
			</font>
			</span> 
			at SysML'18.
		<li>January 2018: Teaching new class! 
	      <a href="ift6085-dl-theory-class/">
		IFT 6085: Theoretical principles for deep learning
		</a>
		<li>December 2017: Accelerated power iteration via momentum, paper accepted at AISTATS 2018.
		<li>November 2017: Talk at Google Brain, Montréal
			<li>September 2017: Thrilled to be starting work at the University of Montreal and the Mila as an assistant professor!
		<li>August 2017: Visiting my alma mater, UT Austin.
		<li>August 2017: At Sydney for ICML, presenting work on YellowFin, custom scans for Gibbs sampling, and deep learning for 3D point cloud representation and generation.
		<li>July 2017: 
			<span style="font-weight:bold">
			<font color="red">
				New preprint!
			</font>
			</span> Representation Learning and Adversarial Generation of 3D Point Clouds
				<a href="https://arxiv.org/abs/1707.02392">[arxiv]</a>.
		<li>July 2017: 
			<span style="font-weight:bold">
			<font color="red">
				New preprint!
			</font>
			</span> Accelerated stochastic power iteration
				<a href="https://arxiv.org/abs/1707.02670">[arxiv]</a>.
		<li>June 2017: 
			<span style="font-weight:bold">
			<font color="red">
				New preprint!
			</font>
			</span> An automatic tuner for they hyperparameters of momentum SGD 
				<a href="https://arxiv.org/pdf/1706.03471.pdf">[arxiv]</a>.
		<li>May 2017: Custom scan sequence paper accepted for presentation at ICML 2017!
		<li>April 2017: Invited talk at Workshop on Advances in Computing Architectures, Stanford SystemX
		<li>March 2017: 
		<span style="font-weight:bold">
		<font color="red">
			New preprint!
		</font>
		</span> Custom scan sequences for 
			<a href="https://arxiv.org/pdf/1707.05807.pdf">super fast Gibbs sampling</a>.
		<li>February 2017: Invited to talk at ITA in San Diego.
		<li>February 2017: Spoke at the AAAI 2017 Workshop on Distributed Machine Learning.
		<li>January 2017: Visiting Microsoft Research, Cambridge
		<li>December 2016: At NIPS, presenting our
			<a href="https://arxiv.org/abs/1606.03432">Gibbs sampling paper</a>
		  	dispelling some common beliefs regarding scan orders.
		<li>November 2016: Visiting Microsoft Research New England
		<li>November 2016: Invited talk at SystemX Stanford Alliance Fall Conference 
		<li>November 2016: Full version of asynchrony <a href="papers/asynchrony-begets-momentum.pdf">paper</a>.
	  	<li>September 2016: Talk at Allerton
	  	<li>August 2016: I had the pleasure to give a talk MIT Lincoln Labs.
	  	<li>August 2016: Gave an <a href="{{ site.baseurl}}/asynchrony/">asynchronous optimization</a> talk at Google.
		<li>August 2016: <a href="http://stanford.edu/~imit/tuneyourmomentum/">Blog post</a> on our momentum work.
	  	<li>July 2016: Invited to talk at NVIDIA.
		<li>June 2016: <a href="{{ site.baseurl}}/asynchrony/">Poster</a> at non-convex optimization ICML <a href="http://sites.google.com/site/noncvxicml16/">workshop</a>.
		<li>June 2016: <a href="https://arxiv.org/abs/1606.07365">Poster</a> at OptML 2016 workshop.
		<li>In a recent <a href="http://bit.ly/22wAt0e">note</a>,
		we show that asynchrony in SGD introduces momentum. 
		In the companion <a href="http://bit.ly/ovore">systems paper</a>, we use this
		theory to train deep networks faster.
		  <li>Does periodic model averaging always help? Recent <a href="https://arxiv.org/abs/1606.07365">results</a>.
		<li>Excited to start Postdoc at Stanford University. Will be working with Lester Mackey and Chris R&eacute;.</li>
		<li>Successfully defended my PhD thesis!</li>
		<li>SILO <a href="http://wid.wisc.edu/featured-events/silo032515/">seminar talk</a> at the Wisconsin Institute of Discovery. Loved both Madison and the WID!</li>
		<li>Densest k-Subgraph work <a href="http://devblogs.nvidia.com/parallelforall/gpu-accelerated-graph-analytics-python-numba/">picked up by NVIDIA</a>!</li>
		<li>Our latest <a href="papers/FrogWild.pdf">work</a> has been accepted for presentation at VLDB 2015!</li>
    </ul>
    </div>
    <br>

    <br>

  <h2>Students and postdocs</h2>

<table style="text-align: left;" border="0">
    <tbody>
      <tr>
        <td style="width=50%;vertical-align: top;">
	<a href="https://bradyneal.github.io/aboutme/" target="_blank">
        <img title="Brady Neal", style="width:20%;" alt="Brady Neal" src="images/person-brady.jpg">
	Brady Neal, PhD 
	</a>
	<br>
	<br>
	<a href="https://scholar.google.ca/citations?user=rZvmqJsAAAAJ&hl=en" target="_blank">
        <img title="Adam Ibrahim", style="width:20%;" alt="Adam Ibrahim" src="images/person-adam.jpg">
	Adam Ibrahim, PhD 
	</a>
	<br>
	<br>
        <img title="Remi Piche-Taillefer", style="width:20%;" alt="Remi Piche-Taillefer" src="images/person-missing.png">
	Remi Piche-Taillefer, MSc
	<br>
	<br>
	<a href="https://www.maths.ed.ac.uk/~s1461357/" target="_blank">
        <img title="Nicolas Loizou", style="width:20%;" alt="Nicolas Loizou" src="images/person-nicolas.jpg">
	Nicolas Loizou, Postdoc
	</a>
	<br>
	<br>
	<a href="https://mathemanu.github.io/" target="_blank">
        <img title="Manuela Girotti", style="width:20%;" alt="Manuela Girotti" src="images/person-manuela.jpeg">
	Manuela Girotti, MSc	
	</a>
	<br>
	<br>
	</td>
        <!--td width=30px></td-->
        <td style="width=50%;vertical-align: top;">
	<a href="https://reyhaneaskari.github.io/" target="_blank">
        <img title="Reyhane Askari-Hemmat", style="width:20%;" alt="Reyhane Askari-Hemmat" src="images/person-reyhane.jpg">
	Reyhane Askari-Hemmat, PhD 
	</a>
	<br>
	<br>
	<a href="https://ajolicoeur.wordpress.com/" target="_blank">
        <img title="Alexia Jolicoeur-Martineau", style="width:20%;" alt="Alexia Jolicoeur-Martineau" src="images/person-alexia.jpg">
	Alexia Jolicoeur-Martineau, PhD 
	</a>
	<br>
	<br>
        <img title="Baptiste Goujeaud", style="width:20%;" alt="Baptiste Goujeaud" src="images/person-missing.png">
	Baptiste Goujeaud, PhD 
	<br>
	<br>
	<a href="https://mila.quebec/en/person/amartya-mitra/" target="_blank">
        <img title="Amartya Mitra", style="width:20%;" alt="Amartya Mitra" src="images/person-amartya.jpg">
	Amartya Mitra, Intern
	</a>
	<br>
	<br>

	</td>
	<td style="vertical-align: top;">&nbsp;&nbsp; <br>
        </td>
      </tr>
    </tbody>
  </table>


    <br>
    <br>


  <h2>Past Students
  (and where they are now) 
</h2>
<table style="text-align: left;" border="0">
    <tbody>
      <tr>
        <td style="width=50%;vertical-align: top;">
	Brady Neal, MSc, Fall 2019 (continuing for PhD)
	<br>
	Seb Arnold, intern, Summer 2018 (PhD candidate at USC)
	<br>
Nicolas Gagne, intern, Summer 2018 (PhD candidate at McGill)
	<br>
Vinayak Tantia, intern, 2018 (Research Engineer at FAIR Montreal)
	</td>
        <td width=30px></td>
        <td style="width=50%;vertical-align: top;">
	</td>
	<td style="vertical-align: top;">&nbsp;&nbsp; <br>
        </td>
      </tr>
    </tbody>
  </table>


    <br>

    <br>

  <h2>Publications</h2>
  <!-- {==% bibtex _plugins/style.bst biblio/biblio.bib %} -->
  {% include biblio.html %}

  <br>
  <br>

  <h2>Older Publications</h2>
  <!-- {==% bibtex _plugins/style.bst biblio/biblio.bib %} -->

  {% include biblio_older.html %}

  <br>

  <h2>Funding Acknowledgements</h2>
        <img title="CIFAR", style="width:15%;" alt="CIFAR" src="images/logo-cifar.jpg">
        <img title="Apogee", style="width:20%;" alt="Apogee" src="images/logo-apogee.png">
        <img title="IVADO", style="width:20%;" alt="IVADO" src="images/logo-ivado.png">
	<br>
        <img title="FRQNT", style="width:18%;" alt="FRQNT" src="images/logo-frqnt.png">
        <img title="NSERC", style="width:18%;" alt="NSERC" src="images/logo-nserc.png">
        <img title="Microsoft Research", style="width:20%;" alt="Microsoft Research" src="images/logo-msr.png">
	<br>
	<br>
	Special thanks to Intel and NVIDIA for donating access to hardware
	and SigOPT for access to their platform for some of our work.
	

<!--   <h1 class="page-heading">Recent News</h1>

  <ul class="post-list">
    {% for post in site.posts %}
      <li>
        <span class="post-meta">{{ post.date | date: "%b %-d, %Y" }}</span>

        <h2>
          <a class="post-link" href="{{ post.url | prepend: site.baseurl }}">{{ post.title }}</a>
        </h2>
      </li>
    {% endfor %}
  </ul> -->

  <!--p class="rss-subscribe">subscribe <a href="{{ "/feed.xml" | prepend: site.baseurl }}">via RSS</a></p-->

</div>
