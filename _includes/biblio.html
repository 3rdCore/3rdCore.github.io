
<dl>

<dt>
<a name="misra2019mish">&nbsp;</a>
</dt>
<dd>
<b>
Mish: A Self Regularized Non-Monotonic Neural Activation Function
</b><br>
Diganta Misra
<br>
BMVC, 2020 [<a href="https://www.bmvc2020-conference.com/assets/papers/0928.pdf">pdf</a>][<a href="https://github.com/digantamisra98/Mish">code</a>][<a href="https://youtu.be/whOdg-yrgdI">CV Talk Episode</a>][<a href="https://open.spotify.com/episode/4sT9sxjSbAKtvJ6hTFg9zc">ML Cafe Episode</a>][<a href="https://youtu.be/T2CRFROKcLM">Sicara Talk</a>][<a href="https://www.youtube.com/watch?v=1U-7TWysqIg">Weights & Biases Salon Episode</a>]
</dd>


<dt>
<a name="misra2021rotate">&nbsp;</a>
</dt>
<dd>
<b>
Rotate to Attend: Convolutional Triplet Attention Module
</b><br>
Diganta Misra, Trikay Nalamada, Ajay Uppili Arasanipalai, Qibin Hou
<br>
WACV, 2021 [<a href="https://openaccess.thecvf.com/content/WACV2021/papers/Misra_Rotate_to_Attend_Convolutional_Triplet_Attention_Module_WACV_2021_paper.pdf">pdf</a>][<a href="https://openaccess.thecvf.com/content/WACV2021/supplemental/Misra_Rotate_to_Attend_WACV_2021_supplemental.pdf">supp</a>][<a href="https://youtu.be/ZW9_2bNF1zo">video</a>][<a href="https://youtu.be/ZW9_2bNF1zo">code</a>]
</dd>


</dl>